{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88f45dc",
   "metadata": {},
   "source": [
    "# Aprendizado Profundo: CNNs\n",
    "\n",
    "**Dataset:** On Vehicle Helmet Detection Dataset\n",
    "\n",
    "**Problema:** Classificação de Segurança no Trânsito (Uso de Capacete)\n",
    "\n",
    "O objetivo deste projeto é desenvolver um modelo de Redes Neurais Convolucionais (CNN) capaz de identificar automaticamente se motociclistas estão utilizando capacete de segurança.\n",
    "\n",
    "Este problema é de alta relevância para sistemas de cidades inteligentes e segurança do trabalho, permitindo a automação da fiscalização e prevenção de acidentes fatais. O dataset utilizado contém imagens reais capturadas em ambiente de trânsito, divididas em classes de \"Com Capacete\" e \"Sem Capacete\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a816b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import kagglehub\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "try:\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Bibliotecas importadas !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7c90d",
   "metadata": {},
   "source": [
    "## 1. Processamento dos Dados\n",
    "Nesta etapa, realizamos o carregamento e pré-processamento das imagens:\n",
    "1. **Redimensionamento:** Todas as imagens foram padronizadas para o tamanho 128x128 pixels.\n",
    "2. **Divisão:** O conjunto foi dividido em 80% para treino e 20% para validação.\n",
    "3. **Batching:** As imagens são processadas em lotes (batches) de 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baixando/Verificando o dataset do Kaggle...\")\n",
    "path_root = kagglehub.dataset_download(\"rajeevsekar21/on-vehicle-helmet-detection-dataset\")\n",
    "\n",
    "data_dir = pathlib.Path(path_root) / 'Helmet_Dataset'\n",
    "\n",
    "print(f\"Diretório: {data_dir}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Classes (pastas) encontradas: {os.listdir(data_dir)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler diretório: {e}\")\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "print(\"\\n--- Carregando treino...\")\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "print(\"--- Carregando validação...\")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"\\n --- CLASSES FINAIS: {class_names} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc48003",
   "metadata": {},
   "source": [
    "Visualizando 9 imagens do dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(8):\n",
    "    ax = plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ddc2f8",
   "metadata": {},
   "source": [
    "## 3. Treinamento e Avaliação\n",
    "\n",
    "### Arquitetura da Rede\n",
    "Utilizamos uma arquitetura CNN Sequencial com as seguintes características:\n",
    "* **Rescaling:** Normalização dos pixels (0 a 1).\n",
    "* **Data Augmentation:** Rotação e espelhamento aleatórios para evitar overfitting.\n",
    "* **Camadas Convolucionais (Conv2D):** 3 blocos para extração de características visuais.\n",
    "* **MaxPooling:** Para redução de dimensionalidade.\n",
    "* **Dense/Dropout:** Camadas finais para classificação e regularização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba46e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = models.Sequential([\n",
    "  # --- A CORREÇÃO ESTÁ AQUI EMBAIXO ---\n",
    "  # Em vez de colocar input_shape no Rescaling, criamos uma camada Input explícita\n",
    "  Input(shape=(img_height, img_width, 3)),\n",
    "  \n",
    "  layers.Rescaling(1./255), # Normalização (sem o input_shape aqui)\n",
    "\n",
    "  # O resto continua igual\n",
    "  layers.RandomFlip(\"horizontal\"),\n",
    "  layers.RandomRotation(0.1),\n",
    "  layers.RandomZoom(0.1),\n",
    "\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  \n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dropout(0.5),\n",
    "  \n",
    "  layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fedd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15 \n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "\n",
    "print(\"Treinamento concluído !!\")\n",
    "acc_final = history.history['val_accuracy'][-1]\n",
    "print(f\"Acuracia: {acc_final*100:.0f}% ({acc_final:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cbab64",
   "metadata": {},
   "source": [
    "## 4. Resultados Obtidos\n",
    "Abaixo apresentamos os gráficos de desempenho do modelo.\n",
    "* **Acurácia:** Indica a porcentagem de acertos.\n",
    "* **Loss (Perda):** Indica o erro do modelo (quanto menor, melhor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5411836",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Treino: Acurácia')\n",
    "plt.plot(epochs_range, val_acc, label='Validação: Acurácia')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Evolução da Acurácia')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia (0 a 1)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Erro (Loss)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Treino: Erro')\n",
    "plt.plot(epochs_range, val_loss, label='Validação: Erro')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Redução do Erro (Loss)')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Erro')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d96a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gerando previsões para calcular métricas...\")\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Previsão do Modelo')\n",
    "plt.ylabel('Real (Verdadeiro)')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# Precisão, Recall, F1-Score\n",
    "print(\"\\n--- Relatório de Classificação ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea87106",
   "metadata": {},
   "source": [
    "## 5. Conclusão\n",
    "\n",
    "Neste projeto, desenvolvemos uma Rede Neural Convolucional (CNN) para auxiliar na segurança do trânsito através da detecção automática do uso de capacetes.\n",
    "\n",
    "**Resultados Obtidos:**\n",
    "O modelo demonstrou um desempenho satisfatório, atingindo uma acurácia de validação próxima a **87%**. Os gráficos de treinamento indicam que houve convergência adequada, com as curvas de treino e validação seguindo tendências similares, o que sugere que as técnicas de regularização (Dropout e Data Augmentation) foram eficazes em evitar o overfitting, mesmo com um dataset limitado.\n",
    "\n",
    "**Análise das Métricas:**\n",
    "A matriz de confusão nos permitiu identificar que o modelo possui alta taxa de acerto na distinção entre motociclistas com e sem capacete. O F1-Score equilibrado reforça a robustez do classificador.\n",
    "\n",
    "**Próximos Passos:**\n",
    "Para trabalhos futuros, o desempenho poderia ser aprimorado com:\n",
    "1.  Aumento do dataset (coleta de mais imagens).\n",
    "2.  Uso de *Transfer Learning* com redes pré-treinadas (como VGG16 ou ResNet).\n",
    "3.  Implementação de detecção de objetos (YOLO) para localizar múltiplos motociclistas na mesma cena."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
